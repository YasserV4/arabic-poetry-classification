{
  "best_global_step": 6500,
  "best_metric": 1.8428142070770264,
  "best_model_checkpoint": "./results/checkpoint-6500",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 29700,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03367003367003367,
      "grad_norm": 13.490579605102539,
      "learning_rate": 3.88e-06,
      "loss": 2.2496,
      "step": 100
    },
    {
      "epoch": 0.06734006734006734,
      "grad_norm": 12.107987403869629,
      "learning_rate": 7.800000000000002e-06,
      "loss": 2.0653,
      "step": 200
    },
    {
      "epoch": 0.10101010101010101,
      "grad_norm": 16.72524070739746,
      "learning_rate": 1.18e-05,
      "loss": 2.1543,
      "step": 300
    },
    {
      "epoch": 0.13468013468013468,
      "grad_norm": 13.67145824432373,
      "learning_rate": 1.576e-05,
      "loss": 2.1112,
      "step": 400
    },
    {
      "epoch": 0.16835016835016836,
      "grad_norm": 12.950204849243164,
      "learning_rate": 1.972e-05,
      "loss": 2.0677,
      "step": 500
    },
    {
      "epoch": 0.16835016835016836,
      "eval_loss": 2.0348055362701416,
      "eval_runtime": 49.8168,
      "eval_samples_per_second": 238.474,
      "eval_steps_per_second": 14.915,
      "step": 500
    },
    {
      "epoch": 0.20202020202020202,
      "grad_norm": 11.40325927734375,
      "learning_rate": 1.9936301369863015e-05,
      "loss": 2.0687,
      "step": 600
    },
    {
      "epoch": 0.2356902356902357,
      "grad_norm": 8.287071228027344,
      "learning_rate": 1.9867808219178084e-05,
      "loss": 2.0163,
      "step": 700
    },
    {
      "epoch": 0.26936026936026936,
      "grad_norm": 10.452594757080078,
      "learning_rate": 1.98e-05,
      "loss": 2.046,
      "step": 800
    },
    {
      "epoch": 0.30303030303030304,
      "grad_norm": 7.630876064300537,
      "learning_rate": 1.973150684931507e-05,
      "loss": 1.9673,
      "step": 900
    },
    {
      "epoch": 0.3367003367003367,
      "grad_norm": 15.079947471618652,
      "learning_rate": 1.966301369863014e-05,
      "loss": 2.0099,
      "step": 1000
    },
    {
      "epoch": 0.3367003367003367,
      "eval_loss": 1.9747573137283325,
      "eval_runtime": 49.8096,
      "eval_samples_per_second": 238.508,
      "eval_steps_per_second": 14.917,
      "step": 1000
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 10.665511131286621,
      "learning_rate": 1.9594520547945205e-05,
      "loss": 1.9808,
      "step": 1100
    },
    {
      "epoch": 0.40404040404040403,
      "grad_norm": 13.532833099365234,
      "learning_rate": 1.9526027397260278e-05,
      "loss": 2.0296,
      "step": 1200
    },
    {
      "epoch": 0.4377104377104377,
      "grad_norm": 7.816136360168457,
      "learning_rate": 1.9457534246575344e-05,
      "loss": 1.9699,
      "step": 1300
    },
    {
      "epoch": 0.4713804713804714,
      "grad_norm": 21.260469436645508,
      "learning_rate": 1.9389041095890414e-05,
      "loss": 1.9583,
      "step": 1400
    },
    {
      "epoch": 0.5050505050505051,
      "grad_norm": 39.267879486083984,
      "learning_rate": 1.932054794520548e-05,
      "loss": 1.9638,
      "step": 1500
    },
    {
      "epoch": 0.5050505050505051,
      "eval_loss": 1.96779465675354,
      "eval_runtime": 49.8871,
      "eval_samples_per_second": 238.138,
      "eval_steps_per_second": 14.894,
      "step": 1500
    },
    {
      "epoch": 0.5387205387205387,
      "grad_norm": 8.646164894104004,
      "learning_rate": 1.925205479452055e-05,
      "loss": 1.934,
      "step": 1600
    },
    {
      "epoch": 0.5723905723905723,
      "grad_norm": 9.303609848022461,
      "learning_rate": 1.918356164383562e-05,
      "loss": 2.0479,
      "step": 1700
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 8.676155090332031,
      "learning_rate": 1.9115068493150685e-05,
      "loss": 1.9307,
      "step": 1800
    },
    {
      "epoch": 0.6397306397306397,
      "grad_norm": 28.682682037353516,
      "learning_rate": 1.9046575342465754e-05,
      "loss": 1.9939,
      "step": 1900
    },
    {
      "epoch": 0.6734006734006734,
      "grad_norm": 23.377696990966797,
      "learning_rate": 1.8978082191780824e-05,
      "loss": 1.9632,
      "step": 2000
    },
    {
      "epoch": 0.6734006734006734,
      "eval_loss": 1.9482526779174805,
      "eval_runtime": 49.7929,
      "eval_samples_per_second": 238.588,
      "eval_steps_per_second": 14.922,
      "step": 2000
    },
    {
      "epoch": 0.7070707070707071,
      "grad_norm": 11.529252052307129,
      "learning_rate": 1.8909589041095893e-05,
      "loss": 2.0263,
      "step": 2100
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 12.035713195800781,
      "learning_rate": 1.884109589041096e-05,
      "loss": 1.9359,
      "step": 2200
    },
    {
      "epoch": 0.7744107744107744,
      "grad_norm": 18.1430606842041,
      "learning_rate": 1.877260273972603e-05,
      "loss": 1.8994,
      "step": 2300
    },
    {
      "epoch": 0.8080808080808081,
      "grad_norm": 20.882036209106445,
      "learning_rate": 1.8704109589041098e-05,
      "loss": 1.9288,
      "step": 2400
    },
    {
      "epoch": 0.8417508417508418,
      "grad_norm": 15.457558631896973,
      "learning_rate": 1.8635616438356164e-05,
      "loss": 1.8975,
      "step": 2500
    },
    {
      "epoch": 0.8417508417508418,
      "eval_loss": 1.9043020009994507,
      "eval_runtime": 49.754,
      "eval_samples_per_second": 238.775,
      "eval_steps_per_second": 14.933,
      "step": 2500
    },
    {
      "epoch": 0.8754208754208754,
      "grad_norm": 8.88461685180664,
      "learning_rate": 1.8567123287671234e-05,
      "loss": 1.9866,
      "step": 2600
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 10.967453002929688,
      "learning_rate": 1.8498630136986303e-05,
      "loss": 1.9514,
      "step": 2700
    },
    {
      "epoch": 0.9427609427609428,
      "grad_norm": 9.455864906311035,
      "learning_rate": 1.8430136986301373e-05,
      "loss": 1.942,
      "step": 2800
    },
    {
      "epoch": 0.9764309764309764,
      "grad_norm": 8.436888694763184,
      "learning_rate": 1.8361643835616442e-05,
      "loss": 1.869,
      "step": 2900
    },
    {
      "epoch": 1.0101010101010102,
      "grad_norm": 8.502140998840332,
      "learning_rate": 1.8293150684931508e-05,
      "loss": 1.8997,
      "step": 3000
    },
    {
      "epoch": 1.0101010101010102,
      "eval_loss": 1.8956189155578613,
      "eval_runtime": 49.7869,
      "eval_samples_per_second": 238.617,
      "eval_steps_per_second": 14.924,
      "step": 3000
    },
    {
      "epoch": 1.0437710437710437,
      "grad_norm": 12.682063102722168,
      "learning_rate": 1.8224657534246578e-05,
      "loss": 1.866,
      "step": 3100
    },
    {
      "epoch": 1.0774410774410774,
      "grad_norm": 7.748659133911133,
      "learning_rate": 1.8156164383561644e-05,
      "loss": 1.8866,
      "step": 3200
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 10.165074348449707,
      "learning_rate": 1.8087671232876713e-05,
      "loss": 1.8317,
      "step": 3300
    },
    {
      "epoch": 1.144781144781145,
      "grad_norm": 10.132362365722656,
      "learning_rate": 1.8019178082191783e-05,
      "loss": 1.9117,
      "step": 3400
    },
    {
      "epoch": 1.1784511784511784,
      "grad_norm": 15.511495590209961,
      "learning_rate": 1.795068493150685e-05,
      "loss": 1.8653,
      "step": 3500
    },
    {
      "epoch": 1.1784511784511784,
      "eval_loss": 1.883626937866211,
      "eval_runtime": 49.9577,
      "eval_samples_per_second": 237.801,
      "eval_steps_per_second": 14.873,
      "step": 3500
    },
    {
      "epoch": 1.2121212121212122,
      "grad_norm": 9.700631141662598,
      "learning_rate": 1.7882191780821922e-05,
      "loss": 1.8922,
      "step": 3600
    },
    {
      "epoch": 1.2457912457912457,
      "grad_norm": 21.094144821166992,
      "learning_rate": 1.7813698630136988e-05,
      "loss": 1.8277,
      "step": 3700
    },
    {
      "epoch": 1.2794612794612794,
      "grad_norm": 9.361124038696289,
      "learning_rate": 1.7745205479452057e-05,
      "loss": 1.8873,
      "step": 3800
    },
    {
      "epoch": 1.3131313131313131,
      "grad_norm": 9.415188789367676,
      "learning_rate": 1.7676712328767123e-05,
      "loss": 1.8441,
      "step": 3900
    },
    {
      "epoch": 1.3468013468013469,
      "grad_norm": 9.557186126708984,
      "learning_rate": 1.7608219178082193e-05,
      "loss": 1.8205,
      "step": 4000
    },
    {
      "epoch": 1.3468013468013469,
      "eval_loss": 1.8954453468322754,
      "eval_runtime": 49.7781,
      "eval_samples_per_second": 238.659,
      "eval_steps_per_second": 14.926,
      "step": 4000
    },
    {
      "epoch": 1.3804713804713804,
      "grad_norm": 12.846924781799316,
      "learning_rate": 1.7539726027397262e-05,
      "loss": 1.7603,
      "step": 4100
    },
    {
      "epoch": 1.4141414141414141,
      "grad_norm": 9.660401344299316,
      "learning_rate": 1.747123287671233e-05,
      "loss": 1.7876,
      "step": 4200
    },
    {
      "epoch": 1.4478114478114479,
      "grad_norm": 15.532200813293457,
      "learning_rate": 1.7402739726027398e-05,
      "loss": 1.8479,
      "step": 4300
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 14.226282119750977,
      "learning_rate": 1.7334246575342467e-05,
      "loss": 1.7341,
      "step": 4400
    },
    {
      "epoch": 1.5151515151515151,
      "grad_norm": 12.414135932922363,
      "learning_rate": 1.7265753424657537e-05,
      "loss": 1.8889,
      "step": 4500
    },
    {
      "epoch": 1.5151515151515151,
      "eval_loss": 1.8924041986465454,
      "eval_runtime": 49.7672,
      "eval_samples_per_second": 238.712,
      "eval_steps_per_second": 14.93,
      "step": 4500
    },
    {
      "epoch": 1.5488215488215489,
      "grad_norm": 24.504924774169922,
      "learning_rate": 1.7197260273972606e-05,
      "loss": 1.8235,
      "step": 4600
    },
    {
      "epoch": 1.5824915824915826,
      "grad_norm": 10.160687446594238,
      "learning_rate": 1.7128767123287672e-05,
      "loss": 1.8991,
      "step": 4700
    },
    {
      "epoch": 1.6161616161616161,
      "grad_norm": 12.71899127960205,
      "learning_rate": 1.7060273972602742e-05,
      "loss": 1.9149,
      "step": 4800
    },
    {
      "epoch": 1.6498316498316499,
      "grad_norm": 12.467428207397461,
      "learning_rate": 1.6991780821917808e-05,
      "loss": 1.9192,
      "step": 4900
    },
    {
      "epoch": 1.6835016835016834,
      "grad_norm": 11.339221000671387,
      "learning_rate": 1.6923287671232877e-05,
      "loss": 1.8239,
      "step": 5000
    },
    {
      "epoch": 1.6835016835016834,
      "eval_loss": 1.8633407354354858,
      "eval_runtime": 49.8114,
      "eval_samples_per_second": 238.5,
      "eval_steps_per_second": 14.916,
      "step": 5000
    },
    {
      "epoch": 1.7171717171717171,
      "grad_norm": 9.020124435424805,
      "learning_rate": 1.6854794520547947e-05,
      "loss": 1.7421,
      "step": 5100
    },
    {
      "epoch": 1.7508417508417509,
      "grad_norm": 12.692806243896484,
      "learning_rate": 1.6786301369863016e-05,
      "loss": 1.8938,
      "step": 5200
    },
    {
      "epoch": 1.7845117845117846,
      "grad_norm": 25.263132095336914,
      "learning_rate": 1.6717808219178086e-05,
      "loss": 1.7947,
      "step": 5300
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 14.105916976928711,
      "learning_rate": 1.6649315068493152e-05,
      "loss": 1.7934,
      "step": 5400
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 7.473210334777832,
      "learning_rate": 1.658082191780822e-05,
      "loss": 1.8037,
      "step": 5500
    },
    {
      "epoch": 1.8518518518518519,
      "eval_loss": 1.9014919996261597,
      "eval_runtime": 49.7726,
      "eval_samples_per_second": 238.686,
      "eval_steps_per_second": 14.928,
      "step": 5500
    },
    {
      "epoch": 1.8855218855218854,
      "grad_norm": 11.816505432128906,
      "learning_rate": 1.6512328767123287e-05,
      "loss": 1.7959,
      "step": 5600
    },
    {
      "epoch": 1.9191919191919191,
      "grad_norm": 25.704059600830078,
      "learning_rate": 1.6443835616438357e-05,
      "loss": 1.8384,
      "step": 5700
    },
    {
      "epoch": 1.9528619528619529,
      "grad_norm": 11.614873886108398,
      "learning_rate": 1.6375342465753426e-05,
      "loss": 1.8211,
      "step": 5800
    },
    {
      "epoch": 1.9865319865319866,
      "grad_norm": 10.042984008789062,
      "learning_rate": 1.6306849315068493e-05,
      "loss": 1.7958,
      "step": 5900
    },
    {
      "epoch": 2.0202020202020203,
      "grad_norm": 10.258088111877441,
      "learning_rate": 1.6238356164383562e-05,
      "loss": 1.8255,
      "step": 6000
    },
    {
      "epoch": 2.0202020202020203,
      "eval_loss": 1.8891774415969849,
      "eval_runtime": 49.7857,
      "eval_samples_per_second": 238.623,
      "eval_steps_per_second": 14.924,
      "step": 6000
    },
    {
      "epoch": 2.053872053872054,
      "grad_norm": 10.692834854125977,
      "learning_rate": 1.616986301369863e-05,
      "loss": 1.801,
      "step": 6100
    },
    {
      "epoch": 2.0875420875420874,
      "grad_norm": 8.985823631286621,
      "learning_rate": 1.61013698630137e-05,
      "loss": 1.7131,
      "step": 6200
    },
    {
      "epoch": 2.121212121212121,
      "grad_norm": 10.761727333068848,
      "learning_rate": 1.603287671232877e-05,
      "loss": 1.6956,
      "step": 6300
    },
    {
      "epoch": 2.154882154882155,
      "grad_norm": 7.906344413757324,
      "learning_rate": 1.5964383561643836e-05,
      "loss": 1.7183,
      "step": 6400
    },
    {
      "epoch": 2.1885521885521886,
      "grad_norm": 11.798110008239746,
      "learning_rate": 1.5895890410958906e-05,
      "loss": 1.6806,
      "step": 6500
    },
    {
      "epoch": 2.1885521885521886,
      "eval_loss": 1.8428142070770264,
      "eval_runtime": 49.7904,
      "eval_samples_per_second": 238.6,
      "eval_steps_per_second": 14.923,
      "step": 6500
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 10.672172546386719,
      "learning_rate": 1.5827397260273972e-05,
      "loss": 1.6916,
      "step": 6600
    },
    {
      "epoch": 2.255892255892256,
      "grad_norm": 7.99100399017334,
      "learning_rate": 1.575890410958904e-05,
      "loss": 1.6689,
      "step": 6700
    },
    {
      "epoch": 2.28956228956229,
      "grad_norm": 13.23615550994873,
      "learning_rate": 1.569041095890411e-05,
      "loss": 1.7166,
      "step": 6800
    },
    {
      "epoch": 2.323232323232323,
      "grad_norm": 13.675775527954102,
      "learning_rate": 1.562191780821918e-05,
      "loss": 1.6898,
      "step": 6900
    },
    {
      "epoch": 2.356902356902357,
      "grad_norm": 14.257811546325684,
      "learning_rate": 1.555342465753425e-05,
      "loss": 1.7207,
      "step": 7000
    },
    {
      "epoch": 2.356902356902357,
      "eval_loss": 1.8746538162231445,
      "eval_runtime": 49.7701,
      "eval_samples_per_second": 238.697,
      "eval_steps_per_second": 14.929,
      "step": 7000
    },
    {
      "epoch": 2.3905723905723906,
      "grad_norm": 38.979679107666016,
      "learning_rate": 1.5484931506849316e-05,
      "loss": 1.6757,
      "step": 7100
    },
    {
      "epoch": 2.4242424242424243,
      "grad_norm": 9.373456001281738,
      "learning_rate": 1.5416438356164386e-05,
      "loss": 1.764,
      "step": 7200
    },
    {
      "epoch": 2.457912457912458,
      "grad_norm": 15.3396635055542,
      "learning_rate": 1.534794520547945e-05,
      "loss": 1.7676,
      "step": 7300
    },
    {
      "epoch": 2.4915824915824913,
      "grad_norm": 15.707245826721191,
      "learning_rate": 1.527945205479452e-05,
      "loss": 1.7579,
      "step": 7400
    },
    {
      "epoch": 2.525252525252525,
      "grad_norm": 13.650765419006348,
      "learning_rate": 1.5210958904109589e-05,
      "loss": 1.7368,
      "step": 7500
    },
    {
      "epoch": 2.525252525252525,
      "eval_loss": 1.8496488332748413,
      "eval_runtime": 49.7928,
      "eval_samples_per_second": 238.589,
      "eval_steps_per_second": 14.922,
      "step": 7500
    },
    {
      "epoch": 2.558922558922559,
      "grad_norm": 11.170835494995117,
      "learning_rate": 1.5142465753424658e-05,
      "loss": 1.7168,
      "step": 7600
    },
    {
      "epoch": 2.5925925925925926,
      "grad_norm": 8.368664741516113,
      "learning_rate": 1.5073972602739728e-05,
      "loss": 1.7429,
      "step": 7700
    },
    {
      "epoch": 2.6262626262626263,
      "grad_norm": 9.539249420166016,
      "learning_rate": 1.5005479452054796e-05,
      "loss": 1.7006,
      "step": 7800
    },
    {
      "epoch": 2.65993265993266,
      "grad_norm": 16.21855354309082,
      "learning_rate": 1.4936986301369865e-05,
      "loss": 1.6874,
      "step": 7900
    },
    {
      "epoch": 2.6936026936026938,
      "grad_norm": 11.496427536010742,
      "learning_rate": 1.4868493150684933e-05,
      "loss": 1.6846,
      "step": 8000
    },
    {
      "epoch": 2.6936026936026938,
      "eval_loss": 1.852515697479248,
      "eval_runtime": 49.7624,
      "eval_samples_per_second": 238.735,
      "eval_steps_per_second": 14.931,
      "step": 8000
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 27.773408889770508,
      "learning_rate": 1.48e-05,
      "loss": 1.6847,
      "step": 8100
    },
    {
      "epoch": 2.760942760942761,
      "grad_norm": 9.137298583984375,
      "learning_rate": 1.473150684931507e-05,
      "loss": 1.7001,
      "step": 8200
    },
    {
      "epoch": 2.7946127946127945,
      "grad_norm": 10.070588111877441,
      "learning_rate": 1.4663013698630138e-05,
      "loss": 1.7234,
      "step": 8300
    },
    {
      "epoch": 2.8282828282828283,
      "grad_norm": 9.253921508789062,
      "learning_rate": 1.4594520547945206e-05,
      "loss": 1.713,
      "step": 8400
    },
    {
      "epoch": 2.861952861952862,
      "grad_norm": 10.00996208190918,
      "learning_rate": 1.4526027397260277e-05,
      "loss": 1.6232,
      "step": 8500
    },
    {
      "epoch": 2.861952861952862,
      "eval_loss": 1.8619325160980225,
      "eval_runtime": 49.7797,
      "eval_samples_per_second": 238.652,
      "eval_steps_per_second": 14.926,
      "step": 8500
    },
    {
      "epoch": 2.8956228956228958,
      "grad_norm": 10.05010986328125,
      "learning_rate": 1.4457534246575345e-05,
      "loss": 1.7555,
      "step": 8600
    },
    {
      "epoch": 2.929292929292929,
      "grad_norm": 8.805974006652832,
      "learning_rate": 1.4389041095890412e-05,
      "loss": 1.7182,
      "step": 8700
    },
    {
      "epoch": 2.962962962962963,
      "grad_norm": 10.604695320129395,
      "learning_rate": 1.432054794520548e-05,
      "loss": 1.6314,
      "step": 8800
    },
    {
      "epoch": 2.9966329966329965,
      "grad_norm": 8.445414543151855,
      "learning_rate": 1.425205479452055e-05,
      "loss": 1.6245,
      "step": 8900
    },
    {
      "epoch": 3.0303030303030303,
      "grad_norm": 19.560123443603516,
      "learning_rate": 1.4183561643835617e-05,
      "loss": 1.5316,
      "step": 9000
    },
    {
      "epoch": 3.0303030303030303,
      "eval_loss": 1.8973628282546997,
      "eval_runtime": 49.7901,
      "eval_samples_per_second": 238.602,
      "eval_steps_per_second": 14.923,
      "step": 9000
    },
    {
      "epoch": 3.063973063973064,
      "grad_norm": 11.276901245117188,
      "learning_rate": 1.4115068493150685e-05,
      "loss": 1.5974,
      "step": 9100
    },
    {
      "epoch": 3.0976430976430978,
      "grad_norm": 13.936235427856445,
      "learning_rate": 1.4046575342465753e-05,
      "loss": 1.5758,
      "step": 9200
    },
    {
      "epoch": 3.1313131313131315,
      "grad_norm": 11.921679496765137,
      "learning_rate": 1.3978082191780824e-05,
      "loss": 1.5884,
      "step": 9300
    },
    {
      "epoch": 3.164983164983165,
      "grad_norm": 10.797968864440918,
      "learning_rate": 1.3909589041095892e-05,
      "loss": 1.5619,
      "step": 9400
    },
    {
      "epoch": 3.1986531986531985,
      "grad_norm": 12.203551292419434,
      "learning_rate": 1.384109589041096e-05,
      "loss": 1.5822,
      "step": 9500
    },
    {
      "epoch": 3.1986531986531985,
      "eval_loss": 1.8663897514343262,
      "eval_runtime": 49.7723,
      "eval_samples_per_second": 238.687,
      "eval_steps_per_second": 14.928,
      "step": 9500
    },
    {
      "epoch": 3.2323232323232323,
      "grad_norm": 13.356171607971191,
      "learning_rate": 1.377260273972603e-05,
      "loss": 1.5437,
      "step": 9600
    },
    {
      "epoch": 3.265993265993266,
      "grad_norm": 9.579690933227539,
      "learning_rate": 1.3704794520547947e-05,
      "loss": 1.5845,
      "step": 9700
    },
    {
      "epoch": 3.2996632996632997,
      "grad_norm": 11.691719055175781,
      "learning_rate": 1.3636301369863014e-05,
      "loss": 1.5043,
      "step": 9800
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 9.464461326599121,
      "learning_rate": 1.3567808219178082e-05,
      "loss": 1.553,
      "step": 9900
    },
    {
      "epoch": 3.3670033670033668,
      "grad_norm": 13.595545768737793,
      "learning_rate": 1.3499315068493153e-05,
      "loss": 1.5079,
      "step": 10000
    },
    {
      "epoch": 3.3670033670033668,
      "eval_loss": 1.8611900806427002,
      "eval_runtime": 49.7828,
      "eval_samples_per_second": 238.637,
      "eval_steps_per_second": 14.925,
      "step": 10000
    },
    {
      "epoch": 3.4006734006734005,
      "grad_norm": 25.913331985473633,
      "learning_rate": 1.3430821917808221e-05,
      "loss": 1.5832,
      "step": 10100
    },
    {
      "epoch": 3.4343434343434343,
      "grad_norm": 13.939177513122559,
      "learning_rate": 1.3362328767123289e-05,
      "loss": 1.6276,
      "step": 10200
    },
    {
      "epoch": 3.468013468013468,
      "grad_norm": 10.844592094421387,
      "learning_rate": 1.3293835616438358e-05,
      "loss": 1.6215,
      "step": 10300
    },
    {
      "epoch": 3.5016835016835017,
      "grad_norm": 17.41138458251953,
      "learning_rate": 1.3225342465753426e-05,
      "loss": 1.6009,
      "step": 10400
    },
    {
      "epoch": 3.5353535353535355,
      "grad_norm": 7.565772533416748,
      "learning_rate": 1.3156849315068494e-05,
      "loss": 1.5425,
      "step": 10500
    },
    {
      "epoch": 3.5353535353535355,
      "eval_loss": 1.8857221603393555,
      "eval_runtime": 49.7739,
      "eval_samples_per_second": 238.679,
      "eval_steps_per_second": 14.928,
      "step": 10500
    },
    {
      "epoch": 3.569023569023569,
      "grad_norm": 11.95301628112793,
      "learning_rate": 1.3088356164383562e-05,
      "loss": 1.5063,
      "step": 10600
    },
    {
      "epoch": 3.602693602693603,
      "grad_norm": 15.902923583984375,
      "learning_rate": 1.3019863013698631e-05,
      "loss": 1.5428,
      "step": 10700
    },
    {
      "epoch": 3.6363636363636362,
      "grad_norm": 12.211661338806152,
      "learning_rate": 1.2951369863013699e-05,
      "loss": 1.5874,
      "step": 10800
    },
    {
      "epoch": 3.67003367003367,
      "grad_norm": 13.23359489440918,
      "learning_rate": 1.2882876712328768e-05,
      "loss": 1.6134,
      "step": 10900
    },
    {
      "epoch": 3.7037037037037037,
      "grad_norm": 13.137435913085938,
      "learning_rate": 1.2814383561643838e-05,
      "loss": 1.5846,
      "step": 11000
    },
    {
      "epoch": 3.7037037037037037,
      "eval_loss": 1.8927217721939087,
      "eval_runtime": 49.8503,
      "eval_samples_per_second": 238.313,
      "eval_steps_per_second": 14.905,
      "step": 11000
    },
    {
      "epoch": 3.7373737373737375,
      "grad_norm": 11.105376243591309,
      "learning_rate": 1.2745890410958906e-05,
      "loss": 1.5172,
      "step": 11100
    },
    {
      "epoch": 3.771043771043771,
      "grad_norm": 7.495925426483154,
      "learning_rate": 1.2677397260273973e-05,
      "loss": 1.509,
      "step": 11200
    },
    {
      "epoch": 3.8047138047138045,
      "grad_norm": 20.4459285736084,
      "learning_rate": 1.2608904109589041e-05,
      "loss": 1.567,
      "step": 11300
    },
    {
      "epoch": 3.8383838383838382,
      "grad_norm": 12.918295860290527,
      "learning_rate": 1.254041095890411e-05,
      "loss": 1.632,
      "step": 11400
    },
    {
      "epoch": 3.872053872053872,
      "grad_norm": 10.104531288146973,
      "learning_rate": 1.2471917808219178e-05,
      "loss": 1.5712,
      "step": 11500
    },
    {
      "epoch": 3.872053872053872,
      "eval_loss": 1.8756053447723389,
      "eval_runtime": 49.7601,
      "eval_samples_per_second": 238.746,
      "eval_steps_per_second": 14.932,
      "step": 11500
    },
    {
      "epoch": 3.9057239057239057,
      "grad_norm": 21.182464599609375,
      "learning_rate": 1.2403424657534246e-05,
      "loss": 1.5311,
      "step": 11600
    },
    {
      "epoch": 3.9393939393939394,
      "grad_norm": 9.27868938446045,
      "learning_rate": 1.2334931506849317e-05,
      "loss": 1.6313,
      "step": 11700
    },
    {
      "epoch": 3.973063973063973,
      "grad_norm": 27.596277236938477,
      "learning_rate": 1.2266438356164385e-05,
      "loss": 1.5393,
      "step": 11800
    },
    {
      "epoch": 4.006734006734007,
      "grad_norm": 18.407060623168945,
      "learning_rate": 1.2197945205479453e-05,
      "loss": 1.4378,
      "step": 11900
    },
    {
      "epoch": 4.040404040404041,
      "grad_norm": 17.537277221679688,
      "learning_rate": 1.213013698630137e-05,
      "loss": 1.3816,
      "step": 12000
    },
    {
      "epoch": 4.040404040404041,
      "eval_loss": 1.9897712469100952,
      "eval_runtime": 49.7579,
      "eval_samples_per_second": 238.756,
      "eval_steps_per_second": 14.932,
      "step": 12000
    },
    {
      "epoch": 4.074074074074074,
      "grad_norm": 15.576781272888184,
      "learning_rate": 1.2061643835616438e-05,
      "loss": 1.408,
      "step": 12100
    },
    {
      "epoch": 4.107744107744108,
      "grad_norm": 10.257373809814453,
      "learning_rate": 1.1993150684931508e-05,
      "loss": 1.4118,
      "step": 12200
    },
    {
      "epoch": 4.141414141414141,
      "grad_norm": 15.6586275100708,
      "learning_rate": 1.1924657534246575e-05,
      "loss": 1.464,
      "step": 12300
    },
    {
      "epoch": 4.175084175084175,
      "grad_norm": 18.853376388549805,
      "learning_rate": 1.1856164383561647e-05,
      "loss": 1.445,
      "step": 12400
    },
    {
      "epoch": 4.2087542087542085,
      "grad_norm": 14.160445213317871,
      "learning_rate": 1.1787671232876714e-05,
      "loss": 1.4536,
      "step": 12500
    },
    {
      "epoch": 4.2087542087542085,
      "eval_loss": 1.9633980989456177,
      "eval_runtime": 49.7313,
      "eval_samples_per_second": 238.884,
      "eval_steps_per_second": 14.94,
      "step": 12500
    },
    {
      "epoch": 4.242424242424242,
      "grad_norm": 13.06076717376709,
      "learning_rate": 1.1719178082191782e-05,
      "loss": 1.5213,
      "step": 12600
    },
    {
      "epoch": 4.276094276094276,
      "grad_norm": 19.071908950805664,
      "learning_rate": 1.165068493150685e-05,
      "loss": 1.4523,
      "step": 12700
    },
    {
      "epoch": 4.30976430976431,
      "grad_norm": 21.076793670654297,
      "learning_rate": 1.158219178082192e-05,
      "loss": 1.3948,
      "step": 12800
    },
    {
      "epoch": 4.343434343434343,
      "grad_norm": 11.176650047302246,
      "learning_rate": 1.1513698630136987e-05,
      "loss": 1.3775,
      "step": 12900
    },
    {
      "epoch": 4.377104377104377,
      "grad_norm": 16.154788970947266,
      "learning_rate": 1.1445205479452055e-05,
      "loss": 1.4235,
      "step": 13000
    },
    {
      "epoch": 4.377104377104377,
      "eval_loss": 1.9264780282974243,
      "eval_runtime": 49.7671,
      "eval_samples_per_second": 238.712,
      "eval_steps_per_second": 14.93,
      "step": 13000
    },
    {
      "epoch": 4.410774410774411,
      "grad_norm": 16.32309341430664,
      "learning_rate": 1.1376712328767123e-05,
      "loss": 1.4006,
      "step": 13100
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 9.749846458435059,
      "learning_rate": 1.1308219178082194e-05,
      "loss": 1.5285,
      "step": 13200
    },
    {
      "epoch": 4.478114478114478,
      "grad_norm": 19.18784523010254,
      "learning_rate": 1.1239726027397262e-05,
      "loss": 1.4937,
      "step": 13300
    },
    {
      "epoch": 4.511784511784512,
      "grad_norm": 17.419553756713867,
      "learning_rate": 1.117123287671233e-05,
      "loss": 1.4606,
      "step": 13400
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 11.719161033630371,
      "learning_rate": 1.1102739726027399e-05,
      "loss": 1.44,
      "step": 13500
    },
    {
      "epoch": 4.545454545454545,
      "eval_loss": 2.0046463012695312,
      "eval_runtime": 49.7453,
      "eval_samples_per_second": 238.816,
      "eval_steps_per_second": 14.936,
      "step": 13500
    },
    {
      "epoch": 4.57912457912458,
      "grad_norm": 26.957775115966797,
      "learning_rate": 1.1034246575342467e-05,
      "loss": 1.3545,
      "step": 13600
    },
    {
      "epoch": 4.6127946127946124,
      "grad_norm": 15.175663948059082,
      "learning_rate": 1.0965753424657534e-05,
      "loss": 1.4274,
      "step": 13700
    },
    {
      "epoch": 4.646464646464646,
      "grad_norm": 52.882774353027344,
      "learning_rate": 1.0897260273972602e-05,
      "loss": 1.4634,
      "step": 13800
    },
    {
      "epoch": 4.68013468013468,
      "grad_norm": 14.277643203735352,
      "learning_rate": 1.0828767123287672e-05,
      "loss": 1.3684,
      "step": 13900
    },
    {
      "epoch": 4.713804713804714,
      "grad_norm": 12.585906028747559,
      "learning_rate": 1.0760273972602741e-05,
      "loss": 1.4269,
      "step": 14000
    },
    {
      "epoch": 4.713804713804714,
      "eval_loss": 1.96454918384552,
      "eval_runtime": 52.7078,
      "eval_samples_per_second": 225.394,
      "eval_steps_per_second": 14.097,
      "step": 14000
    },
    {
      "epoch": 4.747474747474747,
      "grad_norm": 11.752166748046875,
      "learning_rate": 1.069178082191781e-05,
      "loss": 1.4019,
      "step": 14100
    },
    {
      "epoch": 4.781144781144781,
      "grad_norm": 13.250016212463379,
      "learning_rate": 1.0623287671232878e-05,
      "loss": 1.4719,
      "step": 14200
    },
    {
      "epoch": 4.814814814814815,
      "grad_norm": 15.132308959960938,
      "learning_rate": 1.0554794520547946e-05,
      "loss": 1.4932,
      "step": 14300
    },
    {
      "epoch": 4.848484848484849,
      "grad_norm": 13.880751609802246,
      "learning_rate": 1.0486301369863014e-05,
      "loss": 1.4178,
      "step": 14400
    },
    {
      "epoch": 4.882154882154882,
      "grad_norm": 20.751785278320312,
      "learning_rate": 1.0417808219178083e-05,
      "loss": 1.3503,
      "step": 14500
    },
    {
      "epoch": 4.882154882154882,
      "eval_loss": 1.9924275875091553,
      "eval_runtime": 52.5683,
      "eval_samples_per_second": 225.992,
      "eval_steps_per_second": 14.134,
      "step": 14500
    },
    {
      "epoch": 4.915824915824916,
      "grad_norm": 13.82153034210205,
      "learning_rate": 1.0349315068493151e-05,
      "loss": 1.386,
      "step": 14600
    },
    {
      "epoch": 4.94949494949495,
      "grad_norm": 14.497857093811035,
      "learning_rate": 1.0280821917808219e-05,
      "loss": 1.2914,
      "step": 14700
    },
    {
      "epoch": 4.983164983164983,
      "grad_norm": 12.786527633666992,
      "learning_rate": 1.021232876712329e-05,
      "loss": 1.4061,
      "step": 14800
    },
    {
      "epoch": 5.016835016835016,
      "grad_norm": 10.76198959350586,
      "learning_rate": 1.0143835616438358e-05,
      "loss": 1.2951,
      "step": 14900
    },
    {
      "epoch": 5.05050505050505,
      "grad_norm": 23.969804763793945,
      "learning_rate": 1.0075342465753426e-05,
      "loss": 1.3074,
      "step": 15000
    },
    {
      "epoch": 5.05050505050505,
      "eval_loss": 2.0244574546813965,
      "eval_runtime": 49.9436,
      "eval_samples_per_second": 237.868,
      "eval_steps_per_second": 14.877,
      "step": 15000
    },
    {
      "epoch": 5.084175084175084,
      "grad_norm": 27.79056167602539,
      "learning_rate": 1.0006849315068494e-05,
      "loss": 1.316,
      "step": 15100
    },
    {
      "epoch": 5.117845117845118,
      "grad_norm": 9.7847318649292,
      "learning_rate": 9.938356164383563e-06,
      "loss": 1.2816,
      "step": 15200
    },
    {
      "epoch": 5.151515151515151,
      "grad_norm": 12.388595581054688,
      "learning_rate": 9.86986301369863e-06,
      "loss": 1.2813,
      "step": 15300
    },
    {
      "epoch": 5.185185185185185,
      "grad_norm": 10.532443046569824,
      "learning_rate": 9.8013698630137e-06,
      "loss": 1.2357,
      "step": 15400
    },
    {
      "epoch": 5.218855218855219,
      "grad_norm": 11.325759887695312,
      "learning_rate": 9.732876712328768e-06,
      "loss": 1.358,
      "step": 15500
    },
    {
      "epoch": 5.218855218855219,
      "eval_loss": 2.021003007888794,
      "eval_runtime": 52.1736,
      "eval_samples_per_second": 227.701,
      "eval_steps_per_second": 14.241,
      "step": 15500
    },
    {
      "epoch": 5.252525252525253,
      "grad_norm": 18.765117645263672,
      "learning_rate": 9.664383561643836e-06,
      "loss": 1.2806,
      "step": 15600
    },
    {
      "epoch": 5.286195286195286,
      "grad_norm": 9.927927017211914,
      "learning_rate": 9.595890410958905e-06,
      "loss": 1.2538,
      "step": 15700
    },
    {
      "epoch": 5.31986531986532,
      "grad_norm": 10.724894523620605,
      "learning_rate": 9.527397260273975e-06,
      "loss": 1.2632,
      "step": 15800
    },
    {
      "epoch": 5.353535353535354,
      "grad_norm": 10.85043716430664,
      "learning_rate": 9.458904109589043e-06,
      "loss": 1.2798,
      "step": 15900
    },
    {
      "epoch": 5.3872053872053876,
      "grad_norm": 10.1987943649292,
      "learning_rate": 9.39041095890411e-06,
      "loss": 1.31,
      "step": 16000
    },
    {
      "epoch": 5.3872053872053876,
      "eval_loss": 2.0396687984466553,
      "eval_runtime": 50.9728,
      "eval_samples_per_second": 233.065,
      "eval_steps_per_second": 14.576,
      "step": 16000
    },
    {
      "epoch": 5.420875420875421,
      "grad_norm": 17.978635787963867,
      "learning_rate": 9.321917808219178e-06,
      "loss": 1.2505,
      "step": 16100
    },
    {
      "epoch": 5.454545454545454,
      "grad_norm": 18.132097244262695,
      "learning_rate": 9.253424657534248e-06,
      "loss": 1.2639,
      "step": 16200
    },
    {
      "epoch": 5.488215488215488,
      "grad_norm": 10.063863754272461,
      "learning_rate": 9.184931506849315e-06,
      "loss": 1.2514,
      "step": 16300
    },
    {
      "epoch": 5.521885521885522,
      "grad_norm": 5.079747200012207,
      "learning_rate": 9.116438356164385e-06,
      "loss": 1.2867,
      "step": 16400
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 12.383824348449707,
      "learning_rate": 9.047945205479453e-06,
      "loss": 1.2607,
      "step": 16500
    },
    {
      "epoch": 5.555555555555555,
      "eval_loss": 2.055636405944824,
      "eval_runtime": 50.959,
      "eval_samples_per_second": 233.129,
      "eval_steps_per_second": 14.58,
      "step": 16500
    },
    {
      "epoch": 5.589225589225589,
      "grad_norm": 21.371625900268555,
      "learning_rate": 8.97945205479452e-06,
      "loss": 1.299,
      "step": 16600
    },
    {
      "epoch": 5.622895622895623,
      "grad_norm": 19.26397705078125,
      "learning_rate": 8.91095890410959e-06,
      "loss": 1.3512,
      "step": 16700
    },
    {
      "epoch": 5.656565656565657,
      "grad_norm": 9.886881828308105,
      "learning_rate": 8.842465753424658e-06,
      "loss": 1.2629,
      "step": 16800
    },
    {
      "epoch": 5.69023569023569,
      "grad_norm": 36.02156448364258,
      "learning_rate": 8.774657534246575e-06,
      "loss": 1.3133,
      "step": 16900
    },
    {
      "epoch": 5.723905723905724,
      "grad_norm": 23.583160400390625,
      "learning_rate": 8.706164383561645e-06,
      "loss": 1.2924,
      "step": 17000
    },
    {
      "epoch": 5.723905723905724,
      "eval_loss": 2.0422534942626953,
      "eval_runtime": 51.615,
      "eval_samples_per_second": 230.166,
      "eval_steps_per_second": 14.395,
      "step": 17000
    },
    {
      "epoch": 5.757575757575758,
      "grad_norm": 23.59722900390625,
      "learning_rate": 8.637671232876714e-06,
      "loss": 1.3301,
      "step": 17100
    },
    {
      "epoch": 5.7912457912457915,
      "grad_norm": 9.073824882507324,
      "learning_rate": 8.569178082191782e-06,
      "loss": 1.3161,
      "step": 17200
    },
    {
      "epoch": 5.824915824915825,
      "grad_norm": 9.22984790802002,
      "learning_rate": 8.50068493150685e-06,
      "loss": 1.2328,
      "step": 17300
    },
    {
      "epoch": 5.858585858585858,
      "grad_norm": 13.29713249206543,
      "learning_rate": 8.432191780821919e-06,
      "loss": 1.2796,
      "step": 17400
    },
    {
      "epoch": 5.892255892255893,
      "grad_norm": 13.04818344116211,
      "learning_rate": 8.363698630136987e-06,
      "loss": 1.3276,
      "step": 17500
    },
    {
      "epoch": 5.892255892255893,
      "eval_loss": 2.059481620788574,
      "eval_runtime": 50.9711,
      "eval_samples_per_second": 233.073,
      "eval_steps_per_second": 14.577,
      "step": 17500
    },
    {
      "epoch": 5.925925925925926,
      "grad_norm": 24.346723556518555,
      "learning_rate": 8.295205479452055e-06,
      "loss": 1.3018,
      "step": 17600
    },
    {
      "epoch": 5.959595959595959,
      "grad_norm": 22.401906967163086,
      "learning_rate": 8.226712328767124e-06,
      "loss": 1.3085,
      "step": 17700
    },
    {
      "epoch": 5.993265993265993,
      "grad_norm": 14.768537521362305,
      "learning_rate": 8.158219178082194e-06,
      "loss": 1.3064,
      "step": 17800
    },
    {
      "epoch": 6.026936026936027,
      "grad_norm": 9.006680488586426,
      "learning_rate": 8.089726027397261e-06,
      "loss": 1.2339,
      "step": 17900
    },
    {
      "epoch": 6.0606060606060606,
      "grad_norm": 11.043807029724121,
      "learning_rate": 8.021232876712329e-06,
      "loss": 1.1948,
      "step": 18000
    },
    {
      "epoch": 6.0606060606060606,
      "eval_loss": 2.1229450702667236,
      "eval_runtime": 50.8533,
      "eval_samples_per_second": 233.613,
      "eval_steps_per_second": 14.611,
      "step": 18000
    },
    {
      "epoch": 6.094276094276094,
      "grad_norm": 36.675987243652344,
      "learning_rate": 7.952739726027397e-06,
      "loss": 1.1503,
      "step": 18100
    },
    {
      "epoch": 6.127946127946128,
      "grad_norm": 12.556939125061035,
      "learning_rate": 7.884246575342466e-06,
      "loss": 1.128,
      "step": 18200
    },
    {
      "epoch": 6.161616161616162,
      "grad_norm": 22.59589958190918,
      "learning_rate": 7.815753424657536e-06,
      "loss": 1.1857,
      "step": 18300
    },
    {
      "epoch": 6.1952861952861955,
      "grad_norm": 10.993255615234375,
      "learning_rate": 7.747260273972604e-06,
      "loss": 1.1786,
      "step": 18400
    },
    {
      "epoch": 6.228956228956229,
      "grad_norm": 10.780885696411133,
      "learning_rate": 7.678767123287671e-06,
      "loss": 1.1452,
      "step": 18500
    },
    {
      "epoch": 6.228956228956229,
      "eval_loss": 2.1462817192077637,
      "eval_runtime": 49.9054,
      "eval_samples_per_second": 238.051,
      "eval_steps_per_second": 14.888,
      "step": 18500
    },
    {
      "epoch": 6.262626262626263,
      "grad_norm": 20.746334075927734,
      "learning_rate": 7.610273972602741e-06,
      "loss": 1.1819,
      "step": 18600
    },
    {
      "epoch": 6.296296296296296,
      "grad_norm": 19.29509735107422,
      "learning_rate": 7.541780821917809e-06,
      "loss": 1.1025,
      "step": 18700
    },
    {
      "epoch": 6.32996632996633,
      "grad_norm": 25.178844451904297,
      "learning_rate": 7.473287671232877e-06,
      "loss": 1.1654,
      "step": 18800
    },
    {
      "epoch": 6.363636363636363,
      "grad_norm": 14.328486442565918,
      "learning_rate": 7.404794520547945e-06,
      "loss": 1.1196,
      "step": 18900
    },
    {
      "epoch": 6.397306397306397,
      "grad_norm": 9.746731758117676,
      "learning_rate": 7.3363013698630145e-06,
      "loss": 1.1369,
      "step": 19000
    },
    {
      "epoch": 6.397306397306397,
      "eval_loss": 2.1888253688812256,
      "eval_runtime": 49.9547,
      "eval_samples_per_second": 237.816,
      "eval_steps_per_second": 14.873,
      "step": 19000
    },
    {
      "epoch": 6.430976430976431,
      "grad_norm": 15.435813903808594,
      "learning_rate": 7.268493150684932e-06,
      "loss": 1.2873,
      "step": 19100
    },
    {
      "epoch": 6.4646464646464645,
      "grad_norm": 39.320133209228516,
      "learning_rate": 7.2000000000000005e-06,
      "loss": 1.136,
      "step": 19200
    },
    {
      "epoch": 6.498316498316498,
      "grad_norm": 22.207067489624023,
      "learning_rate": 7.131506849315068e-06,
      "loss": 1.1912,
      "step": 19300
    },
    {
      "epoch": 6.531986531986532,
      "grad_norm": 20.194765090942383,
      "learning_rate": 7.063013698630138e-06,
      "loss": 1.2146,
      "step": 19400
    },
    {
      "epoch": 6.565656565656566,
      "grad_norm": 15.554286003112793,
      "learning_rate": 6.994520547945206e-06,
      "loss": 1.183,
      "step": 19500
    },
    {
      "epoch": 6.565656565656566,
      "eval_loss": 2.194275379180908,
      "eval_runtime": 49.9507,
      "eval_samples_per_second": 237.835,
      "eval_steps_per_second": 14.875,
      "step": 19500
    },
    {
      "epoch": 6.5993265993265995,
      "grad_norm": 9.590336799621582,
      "learning_rate": 6.926027397260274e-06,
      "loss": 1.1673,
      "step": 19600
    },
    {
      "epoch": 6.632996632996633,
      "grad_norm": 20.89299964904785,
      "learning_rate": 6.857534246575343e-06,
      "loss": 1.182,
      "step": 19700
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 11.318929672241211,
      "learning_rate": 6.7890410958904114e-06,
      "loss": 1.2058,
      "step": 19800
    },
    {
      "epoch": 6.700336700336701,
      "grad_norm": 2.1321449279785156,
      "learning_rate": 6.72054794520548e-06,
      "loss": 1.2268,
      "step": 19900
    },
    {
      "epoch": 6.7340067340067336,
      "grad_norm": 15.206537246704102,
      "learning_rate": 6.652054794520548e-06,
      "loss": 1.1181,
      "step": 20000
    },
    {
      "epoch": 6.7340067340067336,
      "eval_loss": 2.1845333576202393,
      "eval_runtime": 49.8845,
      "eval_samples_per_second": 238.15,
      "eval_steps_per_second": 14.894,
      "step": 20000
    },
    {
      "epoch": 6.767676767676767,
      "grad_norm": 31.452564239501953,
      "learning_rate": 6.5835616438356165e-06,
      "loss": 1.1551,
      "step": 20100
    },
    {
      "epoch": 6.801346801346801,
      "grad_norm": 21.995962142944336,
      "learning_rate": 6.515068493150686e-06,
      "loss": 1.1949,
      "step": 20200
    },
    {
      "epoch": 6.835016835016835,
      "grad_norm": 26.214221954345703,
      "learning_rate": 6.446575342465754e-06,
      "loss": 1.1934,
      "step": 20300
    },
    {
      "epoch": 6.8686868686868685,
      "grad_norm": 17.846513748168945,
      "learning_rate": 6.378082191780822e-06,
      "loss": 1.1476,
      "step": 20400
    },
    {
      "epoch": 6.902356902356902,
      "grad_norm": 24.087127685546875,
      "learning_rate": 6.30958904109589e-06,
      "loss": 1.1337,
      "step": 20500
    },
    {
      "epoch": 6.902356902356902,
      "eval_loss": 2.19671368598938,
      "eval_runtime": 49.952,
      "eval_samples_per_second": 237.828,
      "eval_steps_per_second": 14.874,
      "step": 20500
    },
    {
      "epoch": 6.936026936026936,
      "grad_norm": 10.57365608215332,
      "learning_rate": 6.24109589041096e-06,
      "loss": 1.2156,
      "step": 20600
    },
    {
      "epoch": 6.96969696969697,
      "grad_norm": 14.107616424560547,
      "learning_rate": 6.172602739726028e-06,
      "loss": 1.1843,
      "step": 20700
    },
    {
      "epoch": 7.0033670033670035,
      "grad_norm": 14.049687385559082,
      "learning_rate": 6.104109589041096e-06,
      "loss": 1.094,
      "step": 20800
    },
    {
      "epoch": 7.037037037037037,
      "grad_norm": 10.611538887023926,
      "learning_rate": 6.035616438356165e-06,
      "loss": 1.0766,
      "step": 20900
    },
    {
      "epoch": 7.070707070707071,
      "grad_norm": 13.93625259399414,
      "learning_rate": 5.967123287671234e-06,
      "loss": 1.0809,
      "step": 21000
    },
    {
      "epoch": 7.070707070707071,
      "eval_loss": 2.234758138656616,
      "eval_runtime": 49.9011,
      "eval_samples_per_second": 238.071,
      "eval_steps_per_second": 14.889,
      "step": 21000
    },
    {
      "epoch": 7.104377104377105,
      "grad_norm": 4.797474384307861,
      "learning_rate": 5.899315068493151e-06,
      "loss": 1.0274,
      "step": 21100
    },
    {
      "epoch": 7.138047138047138,
      "grad_norm": 19.02652931213379,
      "learning_rate": 5.830821917808219e-06,
      "loss": 1.0298,
      "step": 21200
    },
    {
      "epoch": 7.171717171717171,
      "grad_norm": 7.232755661010742,
      "learning_rate": 5.762328767123289e-06,
      "loss": 1.0701,
      "step": 21300
    },
    {
      "epoch": 7.205387205387205,
      "grad_norm": 23.732423782348633,
      "learning_rate": 5.6938356164383565e-06,
      "loss": 1.0747,
      "step": 21400
    },
    {
      "epoch": 7.239057239057239,
      "grad_norm": 11.07174015045166,
      "learning_rate": 5.625342465753425e-06,
      "loss": 1.0808,
      "step": 21500
    },
    {
      "epoch": 7.239057239057239,
      "eval_loss": 2.296691417694092,
      "eval_runtime": 49.9086,
      "eval_samples_per_second": 238.035,
      "eval_steps_per_second": 14.887,
      "step": 21500
    },
    {
      "epoch": 7.2727272727272725,
      "grad_norm": 20.50724220275879,
      "learning_rate": 5.556849315068493e-06,
      "loss": 1.0479,
      "step": 21600
    },
    {
      "epoch": 7.306397306397306,
      "grad_norm": 24.555818557739258,
      "learning_rate": 5.488356164383562e-06,
      "loss": 1.0839,
      "step": 21700
    },
    {
      "epoch": 7.34006734006734,
      "grad_norm": 10.540373802185059,
      "learning_rate": 5.419863013698631e-06,
      "loss": 1.0547,
      "step": 21800
    },
    {
      "epoch": 7.373737373737374,
      "grad_norm": 10.539715766906738,
      "learning_rate": 5.351369863013699e-06,
      "loss": 1.1239,
      "step": 21900
    },
    {
      "epoch": 7.407407407407407,
      "grad_norm": 39.61534881591797,
      "learning_rate": 5.2828767123287674e-06,
      "loss": 1.0748,
      "step": 22000
    },
    {
      "epoch": 7.407407407407407,
      "eval_loss": 2.3039379119873047,
      "eval_runtime": 49.9224,
      "eval_samples_per_second": 237.969,
      "eval_steps_per_second": 14.883,
      "step": 22000
    },
    {
      "epoch": 7.441077441077441,
      "grad_norm": 18.29905891418457,
      "learning_rate": 5.214383561643837e-06,
      "loss": 1.0827,
      "step": 22100
    },
    {
      "epoch": 7.474747474747475,
      "grad_norm": 16.452857971191406,
      "learning_rate": 5.145890410958905e-06,
      "loss": 1.0471,
      "step": 22200
    },
    {
      "epoch": 7.508417508417509,
      "grad_norm": 8.38085651397705,
      "learning_rate": 5.077397260273973e-06,
      "loss": 1.0882,
      "step": 22300
    },
    {
      "epoch": 7.542087542087542,
      "grad_norm": 54.777191162109375,
      "learning_rate": 5.008904109589041e-06,
      "loss": 1.1727,
      "step": 22400
    },
    {
      "epoch": 7.575757575757576,
      "grad_norm": 12.629029273986816,
      "learning_rate": 4.94041095890411e-06,
      "loss": 1.0905,
      "step": 22500
    },
    {
      "epoch": 7.575757575757576,
      "eval_loss": 2.268611192703247,
      "eval_runtime": 49.9428,
      "eval_samples_per_second": 237.872,
      "eval_steps_per_second": 14.877,
      "step": 22500
    },
    {
      "epoch": 7.609427609427609,
      "grad_norm": 14.798380851745605,
      "learning_rate": 4.871917808219178e-06,
      "loss": 1.0932,
      "step": 22600
    },
    {
      "epoch": 7.643097643097643,
      "grad_norm": 12.924452781677246,
      "learning_rate": 4.803424657534247e-06,
      "loss": 1.0642,
      "step": 22700
    },
    {
      "epoch": 7.6767676767676765,
      "grad_norm": 18.550615310668945,
      "learning_rate": 4.734931506849316e-06,
      "loss": 1.0585,
      "step": 22800
    },
    {
      "epoch": 7.71043771043771,
      "grad_norm": 14.512907981872559,
      "learning_rate": 4.666438356164384e-06,
      "loss": 1.1144,
      "step": 22900
    },
    {
      "epoch": 7.744107744107744,
      "grad_norm": 13.165205001831055,
      "learning_rate": 4.597945205479453e-06,
      "loss": 1.1509,
      "step": 23000
    },
    {
      "epoch": 7.744107744107744,
      "eval_loss": 2.292774200439453,
      "eval_runtime": 49.8924,
      "eval_samples_per_second": 238.113,
      "eval_steps_per_second": 14.892,
      "step": 23000
    },
    {
      "epoch": 7.777777777777778,
      "grad_norm": 12.581807136535645,
      "learning_rate": 4.529452054794521e-06,
      "loss": 1.1736,
      "step": 23100
    },
    {
      "epoch": 7.811447811447811,
      "grad_norm": 7.428502559661865,
      "learning_rate": 4.460958904109589e-06,
      "loss": 1.1239,
      "step": 23200
    },
    {
      "epoch": 7.845117845117845,
      "grad_norm": 9.7737398147583,
      "learning_rate": 4.393150684931507e-06,
      "loss": 1.0923,
      "step": 23300
    },
    {
      "epoch": 7.878787878787879,
      "grad_norm": 16.613676071166992,
      "learning_rate": 4.324657534246576e-06,
      "loss": 1.126,
      "step": 23400
    },
    {
      "epoch": 7.912457912457913,
      "grad_norm": 17.014867782592773,
      "learning_rate": 4.256164383561644e-06,
      "loss": 1.072,
      "step": 23500
    },
    {
      "epoch": 7.912457912457913,
      "eval_loss": 2.2887959480285645,
      "eval_runtime": 49.9054,
      "eval_samples_per_second": 238.051,
      "eval_steps_per_second": 14.888,
      "step": 23500
    },
    {
      "epoch": 7.946127946127946,
      "grad_norm": 16.536474227905273,
      "learning_rate": 4.1876712328767125e-06,
      "loss": 1.1247,
      "step": 23600
    },
    {
      "epoch": 7.97979797979798,
      "grad_norm": 17.3990535736084,
      "learning_rate": 4.119178082191781e-06,
      "loss": 1.0996,
      "step": 23700
    },
    {
      "epoch": 8.013468013468014,
      "grad_norm": 11.664434432983398,
      "learning_rate": 4.05068493150685e-06,
      "loss": 1.0685,
      "step": 23800
    },
    {
      "epoch": 8.047138047138047,
      "grad_norm": 13.03650188446045,
      "learning_rate": 3.982191780821918e-06,
      "loss": 1.0211,
      "step": 23900
    },
    {
      "epoch": 8.080808080808081,
      "grad_norm": 14.532442092895508,
      "learning_rate": 3.913698630136987e-06,
      "loss": 1.0312,
      "step": 24000
    },
    {
      "epoch": 8.080808080808081,
      "eval_loss": 2.346668004989624,
      "eval_runtime": 49.9371,
      "eval_samples_per_second": 237.899,
      "eval_steps_per_second": 14.879,
      "step": 24000
    },
    {
      "epoch": 8.114478114478114,
      "grad_norm": 15.10132122039795,
      "learning_rate": 3.845205479452055e-06,
      "loss": 0.9998,
      "step": 24100
    },
    {
      "epoch": 8.148148148148149,
      "grad_norm": 30.90323257446289,
      "learning_rate": 3.776712328767124e-06,
      "loss": 0.9588,
      "step": 24200
    },
    {
      "epoch": 8.181818181818182,
      "grad_norm": 9.939072608947754,
      "learning_rate": 3.708219178082192e-06,
      "loss": 0.9813,
      "step": 24300
    },
    {
      "epoch": 8.215488215488216,
      "grad_norm": 36.96890640258789,
      "learning_rate": 3.6397260273972607e-06,
      "loss": 0.9932,
      "step": 24400
    },
    {
      "epoch": 8.24915824915825,
      "grad_norm": 10.521753311157227,
      "learning_rate": 3.571232876712329e-06,
      "loss": 0.9873,
      "step": 24500
    },
    {
      "epoch": 8.24915824915825,
      "eval_loss": 2.4083285331726074,
      "eval_runtime": 49.9017,
      "eval_samples_per_second": 238.068,
      "eval_steps_per_second": 14.889,
      "step": 24500
    },
    {
      "epoch": 8.282828282828282,
      "grad_norm": 16.26885414123535,
      "learning_rate": 3.5027397260273975e-06,
      "loss": 1.0161,
      "step": 24600
    },
    {
      "epoch": 8.316498316498317,
      "grad_norm": 6.079732418060303,
      "learning_rate": 3.4342465753424657e-06,
      "loss": 1.0011,
      "step": 24700
    },
    {
      "epoch": 8.35016835016835,
      "grad_norm": 14.64637565612793,
      "learning_rate": 3.365753424657535e-06,
      "loss": 1.0268,
      "step": 24800
    },
    {
      "epoch": 8.383838383838384,
      "grad_norm": 21.48323631286621,
      "learning_rate": 3.297260273972603e-06,
      "loss": 1.0404,
      "step": 24900
    },
    {
      "epoch": 8.417508417508417,
      "grad_norm": 11.303275108337402,
      "learning_rate": 3.2287671232876716e-06,
      "loss": 0.9913,
      "step": 25000
    },
    {
      "epoch": 8.417508417508417,
      "eval_loss": 2.3823134899139404,
      "eval_runtime": 49.9408,
      "eval_samples_per_second": 237.882,
      "eval_steps_per_second": 14.878,
      "step": 25000
    },
    {
      "epoch": 8.451178451178452,
      "grad_norm": 11.864075660705566,
      "learning_rate": 3.16027397260274e-06,
      "loss": 1.1082,
      "step": 25100
    },
    {
      "epoch": 8.484848484848484,
      "grad_norm": 5.635498046875,
      "learning_rate": 3.0917808219178085e-06,
      "loss": 1.0042,
      "step": 25200
    },
    {
      "epoch": 8.518518518518519,
      "grad_norm": 10.31888198852539,
      "learning_rate": 3.0232876712328767e-06,
      "loss": 1.0126,
      "step": 25300
    },
    {
      "epoch": 8.552188552188552,
      "grad_norm": 9.422059059143066,
      "learning_rate": 2.9547945205479457e-06,
      "loss": 1.0512,
      "step": 25400
    },
    {
      "epoch": 8.585858585858587,
      "grad_norm": 15.351217269897461,
      "learning_rate": 2.886301369863014e-06,
      "loss": 0.9794,
      "step": 25500
    },
    {
      "epoch": 8.585858585858587,
      "eval_loss": 2.3881027698516846,
      "eval_runtime": 49.9152,
      "eval_samples_per_second": 238.004,
      "eval_steps_per_second": 14.885,
      "step": 25500
    },
    {
      "epoch": 8.61952861952862,
      "grad_norm": 35.602317810058594,
      "learning_rate": 2.8184931506849317e-06,
      "loss": 1.0003,
      "step": 25600
    },
    {
      "epoch": 8.653198653198654,
      "grad_norm": 19.15635871887207,
      "learning_rate": 2.7500000000000004e-06,
      "loss": 1.0265,
      "step": 25700
    },
    {
      "epoch": 8.686868686868687,
      "grad_norm": 17.05825424194336,
      "learning_rate": 2.6815068493150686e-06,
      "loss": 1.0789,
      "step": 25800
    },
    {
      "epoch": 8.72053872053872,
      "grad_norm": 24.895503997802734,
      "learning_rate": 2.6130136986301376e-06,
      "loss": 1.0902,
      "step": 25900
    },
    {
      "epoch": 8.754208754208754,
      "grad_norm": 8.401996612548828,
      "learning_rate": 2.544520547945206e-06,
      "loss": 0.9742,
      "step": 26000
    },
    {
      "epoch": 8.754208754208754,
      "eval_loss": 2.3754360675811768,
      "eval_runtime": 49.9101,
      "eval_samples_per_second": 238.028,
      "eval_steps_per_second": 14.887,
      "step": 26000
    },
    {
      "epoch": 8.787878787878787,
      "grad_norm": 19.66377067565918,
      "learning_rate": 2.476027397260274e-06,
      "loss": 1.028,
      "step": 26100
    },
    {
      "epoch": 8.821548821548822,
      "grad_norm": 5.050203323364258,
      "learning_rate": 2.4075342465753426e-06,
      "loss": 1.0143,
      "step": 26200
    },
    {
      "epoch": 8.855218855218855,
      "grad_norm": 13.664990425109863,
      "learning_rate": 2.3390410958904113e-06,
      "loss": 1.11,
      "step": 26300
    },
    {
      "epoch": 8.88888888888889,
      "grad_norm": 20.34807586669922,
      "learning_rate": 2.2705479452054795e-06,
      "loss": 0.9763,
      "step": 26400
    },
    {
      "epoch": 8.922558922558922,
      "grad_norm": 14.483139991760254,
      "learning_rate": 2.202054794520548e-06,
      "loss": 1.0757,
      "step": 26500
    },
    {
      "epoch": 8.922558922558922,
      "eval_loss": 2.4065499305725098,
      "eval_runtime": 49.8752,
      "eval_samples_per_second": 238.195,
      "eval_steps_per_second": 14.897,
      "step": 26500
    },
    {
      "epoch": 8.956228956228957,
      "grad_norm": 22.51988410949707,
      "learning_rate": 2.1335616438356167e-06,
      "loss": 1.051,
      "step": 26600
    },
    {
      "epoch": 8.98989898989899,
      "grad_norm": 24.215513229370117,
      "learning_rate": 2.065068493150685e-06,
      "loss": 0.9601,
      "step": 26700
    },
    {
      "epoch": 9.023569023569024,
      "grad_norm": 11.801844596862793,
      "learning_rate": 1.9965753424657536e-06,
      "loss": 0.9417,
      "step": 26800
    },
    {
      "epoch": 9.057239057239057,
      "grad_norm": 13.482099533081055,
      "learning_rate": 1.928082191780822e-06,
      "loss": 1.0095,
      "step": 26900
    },
    {
      "epoch": 9.090909090909092,
      "grad_norm": 7.466401100158691,
      "learning_rate": 1.8595890410958906e-06,
      "loss": 0.9426,
      "step": 27000
    },
    {
      "epoch": 9.090909090909092,
      "eval_loss": 2.4202096462249756,
      "eval_runtime": 49.867,
      "eval_samples_per_second": 238.234,
      "eval_steps_per_second": 14.9,
      "step": 27000
    },
    {
      "epoch": 9.124579124579125,
      "grad_norm": 11.131571769714355,
      "learning_rate": 1.791095890410959e-06,
      "loss": 0.9864,
      "step": 27100
    },
    {
      "epoch": 9.158249158249157,
      "grad_norm": 26.657243728637695,
      "learning_rate": 1.7226027397260276e-06,
      "loss": 0.9474,
      "step": 27200
    },
    {
      "epoch": 9.191919191919192,
      "grad_norm": 13.617327690124512,
      "learning_rate": 1.654109589041096e-06,
      "loss": 0.9132,
      "step": 27300
    },
    {
      "epoch": 9.225589225589225,
      "grad_norm": 32.57463073730469,
      "learning_rate": 1.5856164383561645e-06,
      "loss": 0.9741,
      "step": 27400
    },
    {
      "epoch": 9.25925925925926,
      "grad_norm": 18.921215057373047,
      "learning_rate": 1.517123287671233e-06,
      "loss": 0.9086,
      "step": 27500
    },
    {
      "epoch": 9.25925925925926,
      "eval_loss": 2.434556245803833,
      "eval_runtime": 49.8825,
      "eval_samples_per_second": 238.16,
      "eval_steps_per_second": 14.895,
      "step": 27500
    },
    {
      "epoch": 9.292929292929292,
      "grad_norm": 17.1010799407959,
      "learning_rate": 1.4486301369863015e-06,
      "loss": 0.9542,
      "step": 27600
    },
    {
      "epoch": 9.326599326599327,
      "grad_norm": 13.122748374938965,
      "learning_rate": 1.38013698630137e-06,
      "loss": 0.9565,
      "step": 27700
    },
    {
      "epoch": 9.36026936026936,
      "grad_norm": 16.134885787963867,
      "learning_rate": 1.3116438356164385e-06,
      "loss": 0.9105,
      "step": 27800
    },
    {
      "epoch": 9.393939393939394,
      "grad_norm": 8.095430374145508,
      "learning_rate": 1.243150684931507e-06,
      "loss": 0.979,
      "step": 27900
    },
    {
      "epoch": 9.427609427609427,
      "grad_norm": 18.700780868530273,
      "learning_rate": 1.1746575342465754e-06,
      "loss": 0.9887,
      "step": 28000
    },
    {
      "epoch": 9.427609427609427,
      "eval_loss": 2.4405789375305176,
      "eval_runtime": 49.8586,
      "eval_samples_per_second": 238.274,
      "eval_steps_per_second": 14.902,
      "step": 28000
    },
    {
      "epoch": 9.461279461279462,
      "grad_norm": 27.16824722290039,
      "learning_rate": 1.106164383561644e-06,
      "loss": 1.054,
      "step": 28100
    },
    {
      "epoch": 9.494949494949495,
      "grad_norm": 11.300154685974121,
      "learning_rate": 1.0376712328767124e-06,
      "loss": 0.9304,
      "step": 28200
    },
    {
      "epoch": 9.52861952861953,
      "grad_norm": 24.94545555114746,
      "learning_rate": 9.69178082191781e-07,
      "loss": 1.0079,
      "step": 28300
    },
    {
      "epoch": 9.562289562289562,
      "grad_norm": 18.443218231201172,
      "learning_rate": 9.006849315068495e-07,
      "loss": 1.0438,
      "step": 28400
    },
    {
      "epoch": 9.595959595959595,
      "grad_norm": 49.43110275268555,
      "learning_rate": 8.321917808219179e-07,
      "loss": 1.0153,
      "step": 28500
    },
    {
      "epoch": 9.595959595959595,
      "eval_loss": 2.4494106769561768,
      "eval_runtime": 49.8884,
      "eval_samples_per_second": 238.132,
      "eval_steps_per_second": 14.893,
      "step": 28500
    },
    {
      "epoch": 9.62962962962963,
      "grad_norm": 24.73764991760254,
      "learning_rate": 7.636986301369864e-07,
      "loss": 0.9546,
      "step": 28600
    },
    {
      "epoch": 9.663299663299663,
      "grad_norm": 9.76933765411377,
      "learning_rate": 6.952054794520549e-07,
      "loss": 0.9237,
      "step": 28700
    },
    {
      "epoch": 9.696969696969697,
      "grad_norm": 48.756072998046875,
      "learning_rate": 6.267123287671234e-07,
      "loss": 1.0352,
      "step": 28800
    },
    {
      "epoch": 9.73063973063973,
      "grad_norm": 17.459409713745117,
      "learning_rate": 5.582191780821919e-07,
      "loss": 0.9143,
      "step": 28900
    },
    {
      "epoch": 9.764309764309765,
      "grad_norm": 17.21791648864746,
      "learning_rate": 4.897260273972603e-07,
      "loss": 1.0377,
      "step": 29000
    },
    {
      "epoch": 9.764309764309765,
      "eval_loss": 2.4434316158294678,
      "eval_runtime": 49.8706,
      "eval_samples_per_second": 238.216,
      "eval_steps_per_second": 14.899,
      "step": 29000
    },
    {
      "epoch": 9.797979797979798,
      "grad_norm": 26.010805130004883,
      "learning_rate": 4.212328767123288e-07,
      "loss": 0.9746,
      "step": 29100
    },
    {
      "epoch": 9.831649831649832,
      "grad_norm": 10.716668128967285,
      "learning_rate": 3.527397260273973e-07,
      "loss": 0.989,
      "step": 29200
    },
    {
      "epoch": 9.865319865319865,
      "grad_norm": 9.136259078979492,
      "learning_rate": 2.842465753424658e-07,
      "loss": 1.0103,
      "step": 29300
    },
    {
      "epoch": 9.8989898989899,
      "grad_norm": 12.548572540283203,
      "learning_rate": 2.1575342465753428e-07,
      "loss": 0.9657,
      "step": 29400
    },
    {
      "epoch": 9.932659932659933,
      "grad_norm": 12.688383102416992,
      "learning_rate": 1.4726027397260274e-07,
      "loss": 0.9941,
      "step": 29500
    },
    {
      "epoch": 9.932659932659933,
      "eval_loss": 2.455463409423828,
      "eval_runtime": 49.9003,
      "eval_samples_per_second": 238.075,
      "eval_steps_per_second": 14.89,
      "step": 29500
    },
    {
      "epoch": 9.966329966329967,
      "grad_norm": 10.681456565856934,
      "learning_rate": 7.876712328767125e-08,
      "loss": 0.8832,
      "step": 29600
    },
    {
      "epoch": 10.0,
      "grad_norm": 31.78069305419922,
      "learning_rate": 1.0273972602739726e-08,
      "loss": 0.9539,
      "step": 29700
    }
  ],
  "logging_steps": 100,
  "max_steps": 29700,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2502770658430976e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
